<<echo=FALSE>>=
library("survival", quietly=TRUE)
opts_chunk$set(comment=NA, tidy=FALSE, highlight=FALSE, echo=FALSE,
               fig.with=7, fig.height=5.5, fig.path="figures/",
               out.width="\\textwidth", out.height="!", device="pdf",
               cache=FALSE, background="#ffffff",
               size='footnotesize',  
               warning=FALSE, error=FALSE, prompt=TRUE)
options(contrasts= c("contr.treatment", "contr.poly"),
        show.signif.stars = FALSE, continue=" ", width=60)
par(mar=c(4.1, 4.1, 1.1, 1.1))

crisk <- function(what, horizontal = TRUE, ...) {
    nstate <- length(what)
    connect <- matrix(0, nstate, nstate,
                      dimnames=list(what, what))
    connect[1,-1] <- 1  # an arrow from state 1 to each of the others
    if (horizontal) statefig(c(1, nstate-1),  connect, ...)
    else statefig(matrix(c(1, nstate-1), ncol=1), connect, ...)
}

state3 <- function(what, horizontal=TRUE, ...) {
    if (length(what) != 3) stop("Should be 3 states")
    connect <- matrix(c(0,0,0, 1,0,0, 1,1,0), 3,3,
                      dimnames=list(what, what))
    if (horizontal) statefig(1:2, connect, ...)
    else statefig(matrix(1:2, ncol=1), connect, ...)
}

etime <- with(mgus2, ifelse(pstat==0, futime, ptime))
event <- with(mgus2, ifelse(pstat==0, 2*death, 1))
event <- factor(event, 0:2, 
                labels=c("censor", "pcm", "death"))
@ 

\section{Fine-Gray model}
\begin{frame}
  {\Large Fine-Gray model}
\end{frame}

\begin{frame}{Fine-Gray model}
  \begin{itemize}
    \item Lament (wrt hazard models)
      \begin{itemize}
        \item``It's too hard!''
        \item ``I only want the overall effect'' 
        \item  ``What's the p-value?'' 
        \item ``I want my hazard ratios back''
      \end{itemize}
    \item Solution: Pretend it's simple
      \begin{itemize}
        \item Turn the problem into a set of two-state
          survival problems
        \item Solve each separately
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Problem}
\begin{quote}
  We have met the enemy and he is us.  Pogo
\end{quote}

\begin{itemize}
  \item Statisticians and their customers are addicted to a 1 number summary
  \item Reality is rarely so simple
  \item Usual approach is to close our eyes and pretend
    \begin{itemize}
        \item linear model: $E(y) = \beta_0 + \beta_1x_1 + \ldots$
        \item logistic: $E(y) = f\left(\beta_0 + \beta_1x_1 + \ldots\right)$
        \item Cox: $\log(\lambda(t)) = \beta_0(t) +  \beta_1x_1 + \ldots$
    \end{itemize}
  \item This is much harder with multi-state data.
  \end{itemize}
\end{frame}


\begin{frame}
<<FGfig>>=
oldpar <- par(mar=c(5.1, 4.1, 1,.1))
layout(matrix(c(1,1,2,3),2,2))
crisk(c("MGUS", "PCM", "Death"))
crisk(c("MGUS/\nDeath", "PCM"))
crisk(c("MGUS/\nPCM", "Death"))
par(oldpar)
layout(1)
@ 
\end{frame}

\begin{frame}{Cox model}
  In a Poisson model there is a relationship between the cumulative
 hazard $\lambda t$ and the CDF:
 \begin{equation*}
   P(X < t) = \exp(-\lambda t)
 \end{equation*}
 
 An ordinary Cox model has the same relationship.
  \begin{align*}
    \lambda(t) &=  \lambda_0(t) \exp(X\beta) \\
    S(t) &= \exp\left[-\int_0^t\Lambda_0(t) \exp(X\beta) \right] \\
         &= p_1(t)
  \end{align*}
 where state 1 is the entry state. 
 It is somewhat odd that there are simple expressions for the 
 hazard
 of an \emph{having} an event at $t$ and the cumulative probability of 
 \emph{not having} that event by time $t$.
\end{frame}


\begin{frame}{Fine-Gray model}
  Rewrite as
  \begin{align*}
    e^{-\Lambda(t)} &= S(t)\\
     & 1-p_2(t) \\
    \log(-\log(1-p_2(t))) &= B_0(t) + \beta_1 x_1 + \ldots \\
    B_0(t) &= \int_0^t \beta_0(s)ds
  \end{align*}

Looks like complimentary log-log regression
 
\end{frame}

 \begin{frame}{Fine-Gray}
  Ordinary Cox
$$ 1-p_2(t) = p_1(t) = \exp\left[-\int_0^t\Lambda_0(t) \exp(X\beta) \right]$$
The Fine-Gray model assumes that
 \begin{align*}
   1 - p_j(t)  &= \mbox{P(has not yet had event type $j$)} \\
               &=  \exp\left[-\int_0^t\Psi_0(t) \exp(X\beta) \right]
   \end{align*}
 where $\Psi$ is the cumulative ``sub-distribution hazard''.
 
 Why?
 \begin{itemize}
   \item If such a model holds, then $\beta$ has a simple interpretation
     wrt actually attaining a given outcome, independent of the
     others
   \pause \item \emph{If}
 \end{itemize}
\end{frame}

\begin{frame}{FG works on these curves}
<<upside-down>>=
mfit2 <- survfit(Surv(etime, event) ~ sex, data=mgus2)

oldpar <- par(mar=c(5.1, 4.1, 1,.1))
layout(matrix(1:2,1,2), widths=2:1)
plot(mfit2, col=c(1,2,1,2), lty=c(2,2,1,1), fun='cloglog',
     lwd=2, 
     xlab="Months post diagnosis", 
     ylab="log(-log(p))")
legend(1, 0, c("death w/o PCM:f", "death w/o PCM:m", 
                  "PCM:female", "PCM:male"), 
       col=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')

crisk(c("MGUS", "PCM", "Death"))
par(oldpar)
layout(1)
@ 
\end{frame}


\begin{frame}{Computation}
  \begin{itemize}
    \item The Fine-Gray model can be computed by
      \begin{itemize}
        \item Create a special dataset for each outcome.
          \begin{itemize}
            \item Subjects who experience another outcome are
              extended out in time, with decreasing weight
            \item The status variable in the new data is 0/1.
          \end{itemize}
        \item Fit a Cox model to the new data, with the case weights.
      \end{itemize}
    \item Normal model checking can be applied.
    \item Ordinary post-coxph survival curves can be computed, 
      which will be the FG estimates.
    \item Fine and Gray suggest a robust variance, Geskus disagrees.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
<<fg1, echo=TRUE>>=
fdata1 <- finegray(Surv(etime, event) ~ id + age + sex + mspike, 
                   etype = "pcm", data= mgus2)
fdata1[1:4,]
#
dim(mgus2)
dim(fdata1)
#
fgfit1 <- coxph(Surv(fgstart, fgstop, fgstatus) ~ age + sex + mspike,
                weight=fgwt, data= fdata1)
@ 
\end{frame}

\begin{frame}{Fits}
  \begin{center}
    \begin{tabular}{rccc}
      & \multicolumn{2}{c}{Hazard ratio} \\
      & age (decades) & sex (M) & serum M-spike \\  \hline
<<fg2, echo=FALSE, results="asis">>=
fdata2 <- finegray(Surv(etime, event) ~ ., 
                   etype = "death", data= mgus2)
fgfit2 <- coxph(Surv(fgstart, fgstop, fgstatus) ~ age + sex + mspike,
                weight=fgwt, data= fdata2)
sc <- c(10,1,1)
cat("Cox, PCM &", paste(sprintf("%4.2f", exp(coef(cfit1)*sc)), collapse=" & "),
    "\\\\ \n")
cat("Fine-Gray, PCM &", paste(sprintf("%4.2f", exp(coef(fgfit1)*sc)), 
                               collapse=" & "), "\\\\ \n")
cat("Cox, death &", paste(sprintf("%4.2f", exp(coef(cfit2)*sc)), collapse=" & "),
    "\\\\ \n")
cat("Fine-Gray, death&", paste(sprintf("%4.2f", exp(coef(fgfit2)*sc)), 
                              collapse=" & "), "\n")
@ 
\end{tabular}
\end{center}
The raw estimates of PCM risk at 15 years were 9.5 and 8 percent for females
and males, respectively, a ratio of 0.84.
\end{frame}

\begin{frame}{Predicted outcome}
<<fg3>>=
newdata <- expand.grid(sex=c("F", "M"), age=c(60, 80), mspike=1.2)
fsurv1 <- survfit(fgfit1, newdata)  # time to progression curves
plot(fsurv1, xscale=12, col=1:2, lty=c(1,1,2,2), lwd=2, fun='event',
     xlab="Years", ylab="Predicted PCM, Fine-Gray",
     xmax=12*25, ylim=c(0, .15))
legend(1, .15, c("Female, 60", "Male, 60","Female: 80", "Male, 80"),
       col=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')
@ 
\end{frame}

\begin{frame}
<<fg4>>=
# these were fit in the mgus section, reprise them
cfit1 <- coxph(Surv(etime, event=="pcm") ~ age + sex+ mspike, 
               data= mgus2)
cfit2 <- coxph(Surv(etime, event=="death") ~ age + sex+ mspike, 
               data= mgus2)
temp <- matrix(list(), 3,3)
temp[1,2] <- list(survfit(cfit1, newdata, std.err=FALSE))
temp[1,3] <- list(survfit(cfit2, newdata, std.err=FALSE))
csurv  <- survfit(temp, p0 =c(entry=1, PCM=0, death=0))

# now to our plot
par(mfrow=c(1,2))
plot(fsurv1, xscale=12, col=1:2, lty=c(1,1,2,2), lwd=2, fun='event',
     xlab="Years", ylab="Predicted PCM, Fine-Gray", 
     xmax=12*25, ylim=c(0, .15))
legend(1, .15, c("Female, 60", "Male, 60","Female: 80", "Male, 80"),
       col=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')

plot(csurv[,2], xscale=12, col=1:2, lty=c(1,1,2,2), lwd=2,
     xlab="Years", ylab="Predicted PCM, rate models", 
     xmax=12*25, ylim=c(0, .15))
legend(1, .15, c("Female, 60", "Male, 60","Female: 80", "Male, 80"),
       col=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')
par(mfrow=c(1,1))
@ 
\end{frame}

\begin{frame}{Which one is right?}
  \begin{itemize}
    \item Compare the predictions to the raw data using population
      averages  (direct adjusted survival curves).
    \item Total
    \begin{enumerate}
      \item For all n=\Sexpr{nrow(mgus2)} subjects in the data set get
        a predicted survival under the FG model
      \item Average the survival curves.
      \item Plot along with the AJ estimate from raw data.
    \end{enumerate}
    \item Within ages: split the data at age 72 (median), repeat for each
      half separately.
  \end{itemize}
\end{frame}

\begin{frame}{Direct adjusted curves, total}
<<direct>>=
tdata <- na.omit(mgus2[,c("age", "sex", "mspike")])
tdata$sex <- 'F'
fd1 <- survfit(fgfit1, tdata)
tdata$sex <- 'M'
fd2 <- survfit(fgfit1, tdata)

plot(mfit2[,1],  xmax=25*12, xscale=12, col=1:2, lwd=2,
     xlab="Years from MGUS", ylab="PCM")
     
temp <- fd1
temp$surv <- rowMeans(temp$surv)
lines(temp, fun="event", col=1, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)
temp <- fd2
temp$surv <- rowMeans(temp$surv)
lines(temp, fun="event", col=2, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)
@ 
\end{frame}

\begin{frame}{Direct adjusted curves, by age}
<<direct2>>=

mfit3 <- survfit(Surv(etime, event) ~ sex + I(age >72), mgus2)

par(mfrow=c(1,2))
plot(mfit3[c(1,3),1], xmax=25*12, xscale=12, col=1:2, lwd=2,
     xlab="Years from MGUS", ylab="PCM")
text(60, .13, "Age <=72", cex=1.25)    
temp <- fd1
temp$surv <- rowMeans(temp$surv[,tdata$age <=72])
lines(temp, fun="event", col=1, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)
temp <- fd2
temp$surv <- rowMeans(temp$surv[, tdata$age <=72])
lines(temp, fun="event", col=2, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)

plot(mfit3[c(2,4),1], xmax=25*12, xscale=12, col=1:2, lwd=2,
     xlab="Years from MGUS", ylab="PCM", ylim=c(0, .148))
text(60, .13, "Age >72", cex=1.25)    
     
temp <- fd1
temp$surv <- rowMeans(temp$surv[,tdata$age >72])
lines(temp, fun="event", col=1, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)
temp <- fd2
temp$surv <- rowMeans(temp$surv[, tdata$age >72])
lines(temp, fun="event", col=2, lty=3, xmax=25*12, lwd=2, conf.int=FALSE)
par(mfrow=c(1,1))   
@ 
\end{frame}

\begin{frame}{Assumptions}
  \begin{itemize}
    \item The risk fits assume a Cox model with linear age and mspike
      effects, additivity, and proportional hazards. \\
      For both PCM and death risks, but separately.
    \item The Fine-Gray fits assume a Cox model with linear age and
      mspike effects, additivity, and proportional hazards. \\
      For the subdistribution PCM and subdistribution death effects.
    \item They can't both be true.
      \pause
    \item Model checking is imperative.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Testing PH}
<<linear, echo=TRUE>>=
cox.zph(cfit1)
#
cox.zph(fgfit1)
@ 
\end{frame}

\begin{frame}
  \begin{itemize}
    \item Look at the predicted fraction who are still endpoint free.
    \item This is a natural part of the AJ estimate. 
    \item The two FG estimates are separate computations; add them.
  \end{itemize}
<<fgsum>>=
fsurv2 <- survfit(fgfit2, newdata)  # time to progression curves
xtime <- 0:(25*12)  #40 years
y1a <- 1 -summary(fsurv1, times=xtime)$surv  #predicted pcm
y1b <- 1 -summary(fsurv2, times=xtime)$surv #predicted deaths before pcm
y1  <- (y1a + y1b)  #neither

matplot(xtime/12, y1, col=1:2, lty=c(1,1,2,2), type='l', lwd=2,
        xlab="Years post diagnosis", ylab="FG: death or PCM")
abline(h=1, col=3)
legend(16, .4, c("Female, 60", "Male, 60","Female: 80", "Male, 80"),
       col=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')
@ 
\end{frame}

\begin{frame}{What would an FH hazard look like?}
<<srate1>>=
# simple model for death rates
drate <- survexp.mn[as.character(60:100), 1:2, "2005"] * 365.25  # death rate
tdata <- expand.grid(age=60:100, male=1:0)  # 1 = males
fit <- lm(log(c(drate)) ~ age + male, tdata)
matplot(60:100, drate*1000, log='y', col=2:1, pch='mf', 
        xlab="Age", ylab="Deaths/1000")
yhat <- 1000* exp(predict(fit, newdata=expand.grid(male=0:1, age=c(60,100))))
segments(c(60, 60), yhat[1:2], c(100,100), yhat[3:4], lty=1, col=1:2)
@ 
\end{frame}

\begin{frame}
<<srate2>>=
matplot(fsurv1$time/12, fsurv1$cumhaz, type='s', lwd=2, col=1:4, lty=1,
        xlab="Years since MGUS", ylab="Cumulative PCM sub-distribution hazard")
legend(1, .2, c("F 60", "M 60", "F 80", "M 80"), lwd=2, lty=1, col=1:4, bty='n')
@ 
\end{frame}

\begin{frame}
  Formula 5.56 of Beyersmann, Allignol, and Schumacher
 $$
  \alpha_1(t) = \frac{\lambda_1(t) \exp \left(-\Lambda_1(t) + A_2(t)\right) }
    { 1- \int_1^t \lambda_1(u) \exp\left( -\Lambda_1(u) + A_2(u)\right) du }
$$
    \begin{itemize}
      \item$\alpha_1, \alpha_2$ = hazard for PCM and death
      \item $\lambda_1$ = subdistribution hazard for PCM
    \end{itemize}
\begin{align*}    
    \alpha_2(t) &= \exp(-11.5 + .105(a + t) + .37m \\
    A_2(t) &=  \exp(-11.5 + .37m + .105a) \left(\exp(.105t) -1 \right)/.105
\end{align*}
\end{frame}

\begin{frame}
<<srate3>>=
# over 30 years
x <- seq(0, 20, length=21)   # sufficient plot points, one year increment
lmat <- Lmat <- Amat <- matrix(0, 21, 4)
amat <- lmat
for (i in 1:4) {
    temp <- smooth.spline(fsurv1$time/12, fsurv1$cumhaz[,i], df=4)
    lmat[,i] <- predict(temp, x=x, deriv=1)$y
    Lmat[,i] <- predict(temp, x=x)$y
    Amat[,i] <- exp(-11.5 + .105*newdata$age[i] + .37*(newdata$sex[i]=='M')) *
         (exp(.105*x) -1)/ .105
}
temp <- lmat * exp(Amat-Lmat)
trap <- rbind(0, (temp[-1,] + temp[-21,])/2)  #integral, by trapezoid rule
amat <- temp/ (1- trap)
matplot(x, amat, type='l', lty=1, lwd=2, col=1:4, log='y',
        xlab="Years after enrollment", ylab="hazard of PCM")
legend(1, .2, c("F 60", "M 60", "F 80", "M 80"), lwd=2, lty=1, col=1:4, bty='n')
@ 
\end{frame}

\begin{frame}{Why the simple model fails for multi-state data}
  \begin{itemize}
    \item Hazards are non-linear
      \begin{enumerate}
      \item In actuality there are multiple hazard operating for a subject,
      each with its own covariates
      \begin{equation*}
        \lambda(t) = \lambda_1(t)e^{X\beta} + \lambda_2(t)e^{Z\gamma} +
        \lambda_3(t) e^{W\psi} + \ldots
      \end{equation*}
    \item PH is a model for $\log(\lambda)$, which does not add nicely.
      Multi-hazards don't collapse to a single PH equation.
    \item The hazard for a heterogeneous collection of subjects is not the
      average of their hazards.  
      \end{enumerate}
    \item Ordinary modeling issues are more acute
      \begin{enumerate}
        \item Proportional hazards rarely holds over long time periods
        \item Non-linearity and interactions will often be substantial
        \item Time dependent covariates are common and with particular
          opportunities for misuse
        \item Episodic follow-up processes.
        \item Informative censoring
      \end{enumerate}
    \item Model checks are imperative
  \end{itemize}
\end{frame}

\begin{frame}{Fine-Gray}
  \begin{itemize}
    \item The model often doesn't fit
      \begin{itemize}
        \item Failure of PH on this scale
        \item Particularly with long follow-up
        \item Does not extend to other multi-state models
      \end{itemize}
      
    \item Wrong interpretation
      \begin{itemize}
        \item HR of .8 for sex; PCM is then interpreted as females have
          a higher rate, i.e., different biology.
        \item We treat it as though it were a HR on one of the arrows
      \end{itemize}
      
    \item Odd 
      \begin{itemize}
        \item Rate model is focused on events/(\# at risk for the event)
        \item FH is focused on events/(\# who have not yet had the event) \\
          over time the denominator has more and more subjects who 
          can never have the event
        \item There is no obvious biological story that will act this
          way. 
      \end{itemize}
      \pause
      \item However
        \begin{itemize}
          \item If the fraction with no endpoint is $>80$\% the fit
            will often be ``okay''
        \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Survival of the FG model?}
  \begin{itemize}
    \item Has a 18 year lead on using a rate model + $p(t)$
    \item It takes us 20 years for statisticians to catch on
    \item In the mind of many researchers FG is \emph{the} way to deal
      with CR.
    \item FG is in R, Stata, and even SAS
  \end{itemize}
  \pause
  
    Overall, SAS is about 11 years behind R and S-Plus in statistical 
    capabilities
 (last year it was about 10 years behind) in my estimation.
    
   -- Frank Harrell (SAS User, 1969-1991)
      R-help (September 2003)
\end{frame}

